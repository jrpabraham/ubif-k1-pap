anova(rs4e, rs4f, refit=FALSE)
rs4a = lmer(wordsprod ~ poly(time0,2)*sex + (1 + poly(time0, 2) | Sub), data=d0, REML=TRUE)
summary(rs4a) # Best model
contrasts(d0$sex) = cbind(Male=c(0,1)); contrasts(d0$sex) # Male=0
rs4a_m = lmer(wordsprod ~ poly(time0,2)*sex + (1 + poly(time0, 2) | Sub), data=d0)
summary(rs4a_m)
contrasts(d0$sex) = cbind(Female=c(1,0)); contrasts(d0$sex) # Female=0
rs4a_f = lmer(wordsprod ~ poly(time0,2)*sex + (1 + poly(time0, 2) | Sub), data=d0)
summary(rs4a_f)
contrasts(d0$sex)
contrasts(d0$sex) = c(-1,1)
contrasts(d0$sex)
rs1b = lmer(wordsprod ~ sex + (1 | Sub), data=d0, REML=FALSE)
summary(rs1b)
contrasts(d0$sex) = c(-1,1)
rs1b = lmer(wordsprod ~ sex + (1 | Sub), data=d0, REML=FALSE)
summary(rs1b)
sem <- function(x) {sd(x) / sqrt(length(x))}
ms <- aggregate(wordsprod ~ timecat + sex, data=d0, FUN=mean)
ms$errs <- aggregate(wordsprod ~ timecat + sex, data=d0, FUN=sem)$wordsprod
print(ms)
sem <- function(x) {sd(x) / sqrt(length(x))}
ms <- aggregate(wordsprod ~ sex, data=d0, FUN=mean)
ms$errs <- aggregate(wordsprod ~ sex, data=d0, FUN=sem)$wordsprod
print(ms)
d0 = read.csv('http://web.stanford.edu/class/psych252/_downloads/vocab0.csv', header = TRUE)
str(d0)
# factor sex
d0$sex = factor(d0$sex, labels = c('Male', 'Female'))
rs1b = lmer(wordsprod ~ sex + (1 | Sub), data=d0, REML=FALSE)
summary(rs1b)
d0_sample$time_quad = I(scale(d0_sample$time0)^2)
d0$Sub = factor(d0$Sub)
d0$timecat = factor(d0$time0, labels = c('18', '21', '24', '30'))
?barplot
barplot(prop.table(table(dc$educcat, dc$agecat)), color=educcat)
barplot(prop.table(table(dc$educcat, dc$agecat)), color=dc$educcat)
?barplot
ggplot(dc, aes(x = agecat)) + geom_bar(aes(fill = educcat))
barplot(prop.table(table(dc$educcat, dc$agecat)), color=dc$educcat)
ggplot(dc, aes(x = agecat)) + geom_bar(aes(fill = educcat))
ggplot(dc, aes(x = educcat)) + geom_bar(aes(fill = count))
ggplot(dc, aes(x = educcat)) + geom_bar(aes(fill = numbers))
ggplot(dc, aes(x = educcat)) + geom_bar()
ggplot(dc, aes(x = educcat)) + geom_bar()
d <- read_csv("http://langcog.stanford.edu/scales_data.csv")
```
d <- read_csv("http://langcog.stanford.edu/scales_data.csv")
library(tidyverse)
d <- read_csv("http://langcog.stanford.edu/scales_data.csv")
head(d)
unique(d$condition)
unique(d$age.group)
ggplot(g, aes(x=age)) +
geom_histogram()
ggplot(d, aes(x=age)) +
geom_histogram()
ggplot(d, aes(x=age)) +
geom_histogram(binwidth = 0.25)
d %>%
group_by(subid) #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n())
d %>%
group_by(subid, condition, age.group) #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) # n is a fxn that counts the number of things
arrange_by(age.group)
unique(d$condition)
unique(d$age.group)
length(unique(d$subid))
d %>%
group_by(subid) #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n())
rm(list =ls())
library(tidyverse)
d <- read_csv("http://langcog.stanford.edu/scales_data.csv")
head(d)
d %>%
group_by(subid) #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n())
d %>%
group_by(subid) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n())
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange_by(age.group)
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group)
d %>%
group_by(condition, age.group) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group)
d %>%
group_by(condition, age.group) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group) %>%
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age   group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group) %>%
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group) %>%
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group)) %>% #for each subid, each condition, each age group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group) %>%
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
arrange(age.group) %>%
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age group, we are going to do something to it
summarise(n_observations = n()) %>% # n is a fxn that counts the number of things
distinct #retains only distinct combos of subid and age group
d %>%
group_by(subid, condition, age.group) %>% #for each subid, each condition, each age group, we are going to do something to it
distinct() %>% #retains only distinct combos of subid and age group
group_by(condition, age.group) %>%
summarise(n_subs = n())# n is a fxn that counts the number of things
d %>%
distinct(subid, condition, age.group) %>% #for each subid, each condition, each   age group, we are going to do something to it, #retains only distinct combos of   subid and age group
group_by(condition, age.group) %>%
summarise(n_subs = n()) # n is a fxn that counts the number of things, this is   removing data (the most granular var)
ggplot(d, aes(x=age, y=correct))
ggplot(d, aes(x=age, y=correct, col = condition))
ggplot(d, aes(x=age, y=correct, col = condition))
ggplot(d, aes(x=age.group, y=correct, col = condition))
ggplot(d, aes(x=age, y=correct, col = condition))
+ geom_point()
ggplot(d, aes(x=age, y=correct, col = condition)) +
geom_point()
ggplot(d, aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
ggplot(d, aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth(method=glm)
# this describes the mean correctness (%correct) by age
ms <- d %>% # getting means. could label "sub_means"
group_by(condition, age, subid) %>%
summarise(correct = mean(correct))
ms <- d %>% # getting means. could label "sub_means"
group_by(condition, age, subid) %>%
summarise(correct = mean(correct)) %>%
group_by(condition, age.group)
ms <- d %>% # getting means. could label "sub_means"
group_by(condition, age, subid) %>%
summarise(correct = mean(correct)) %>%
group_by(condition, age.group) %>%
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ms
sub_means <- d %>% # getting means
group_by(condition, age, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) %>% # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
ms
sub_means <- d %>% # getting means
group_by(condition, age, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) %>% # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
sub_means <- d %>% # getting means
group_by(condition, age, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) %>% # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
sub_means <- d %>% # getting means
group_by(condition, age, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_smooth()
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age.group, y=correct, col = condition)) +
geom_point() +
geom_smooth()
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age.group, y=correct, col = condition)) +
geom_point()
sub_means <- d %>% # getting means
group_by(condition, age subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point()
sub_means <- d %>% # getting means
group_by(condition, age subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point()
sub_means <- d %>% # getting means
group_by(condition, age subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_line() +
ylim(c(0,1)) +
ggthemes::theme_few() +
xlab("Age (Years)")
sub_means <- d %>% # getting means
group_by(condition, age subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_line() +
ylim(c(0,1)) +
# ggthemes::theme_few() +
xlab("Age (Years)")
sub_means <- d %>% # getting means
group_by(condition, age, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age, y=correct, col = condition)) +
geom_point() +
geom_line() +
ylim(c(0,1)) +
# ggthemes::theme_few() +
xlab("Age (Years)")
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct))
ggplot(sub_means,
aes(x=age.group, y=correct, col = condition)) +
geom_point() +
geom_line() +
ylim(c(0,1)) +
# ggthemes::theme_few() +
ylab("Proportion of Responses Correct")
xlab("Age (Years)")
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = means(correct))
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) %>%
summarise(correct = mean(correct))
ggplot(sub_means,
aes(x=age.group, y=correct, col = condition)) +
geom_point() +
geom_line() +
ylim(c(0,1)) +
# ggthemes::theme_few() +
ylab("Proportion of Responses Correct")
xlab("Age (Years)")
sub_means <- d %>% # getting means
group_by(condition, age.group, subid) %>% # it removes the last var granularity
summarise(correct = mean(correct)) %>%
summarise(correct = mean(correct)) # this is the grand mean when all Ss have the same no. of obs. this is bc Ss are weighed by observations rather than Ss.
ggplot(sub_means,
aes(x=age.group, y=correct, col = condition)) +
geom_point +
geom_line +
ylim(c(0,1)) +
# ggthemes::theme_few() +
ylab("Proportion of Responses Correct")
xlab("Age (Years)")
library(forcats)
mtcars
mtcars %>%
# gather(variable, value, columns_to_gather)
gather(variable, value, mpg:carb)
library(tidyverse)
mtcars %>%
# gather(variable, value, columns_to_gather)
gather(variable, value, mpg:carb)
mtcars %>%
mutate(car = rownames(mtcars)) %>%
# gather(variable, value, columns_to_gather)
gather(variable, value, mpg:carb)
tidycars <- mtcars %>%
mutate(car = rownames(mtcars)) %>%
# gather(variable, value, columns_to_gather)
gather(variable, value, mpg:carb)
ggplot(tidycars,
aes(x=value)) +
geom_histogram()
ggplot(tidycars,
aes(x=value)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~variable)
ggplot(tidycars,
aes(x=value)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~variable, scales = "free_x")
mtcars
ggplot(tidycars,
aes(x=value, fill=cars)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~variable, scales = "free_x")
ggplot(tidycars,
aes(x=value, fill=cars)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~variable, scales = "free_x")
tidycars <- mtcars %>%
mutate(car = rownames(mtcars)) %>%
# gather(variable, value, columns_to_gather)
gather(measurement, value, mpg:carb) %>%
separate(car, into=c("make", "model")) #will sep by spaces by default
head(tidycars)
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~variable, scales = "free_x")
facet_wrap(~measurement, scales = "free_x")
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~measurement, scales = "free_x")
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(~measurement, scales = "free_x")
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(make~measurement, scales = "free_x")
ggplot(filter(tidycars, make %in% c("Merc", "Toyota")), #filter
aes(x=value, fill=make) +
geom_histogram() +
facet_wrap(~measurement, scales="free_x")
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(make~measurement, scales = "free_x")
ggplot(filter(tidycars, make %in% c("Merc", "Toyota")), #filter
aes(x=value, fill=make) +
geom_histogram() +
facet_wrap(~measurement, scales="free_x")
ggplot(filter(tidycars, make %in% c("Merc", "Toyota")), #filter
aes(x=value, fill=make) +
geom_histogram() +
facet_wrap(~measurement, scales="free_x")
tidycars <- mtcars %>%
mutate(car = rownames(mtcars)) %>%
# gather(variable, value, columns_to_gather)
gather(measurement, value, mpg:carb) %>%
separate(car, into=c("make", "model")) #will sep by spaces by default
head(tidycars)
ggplot(tidycars,
aes(x=value, fill=make)) +
geom_histogram() + # this is just of all values of all vars. dont do this. use   facets.
facet_wrap(make~measurement, scales = "free_x")
ggplot(filter(tidycars, make %in% c("Merc", "Toyota")), #filter
aes(x=value, fill=make) +
geom_histogram() +
facet_wrap(~measurement, scales="free_x")
head(iris)
head(iris)
head(iris)
tidy_iris <- iris %>%
mutate(observation = 1:n()) #so all obs are on its own row
head(tidy_iris)
head(tidy)
#gather(1. variable (name of col names), 2. value (thing in the cols), 3. range of columns (that select what we want))
tidy_iris <- iris %>%
mutate(observation = 1:n()) %>% #so all obs are on its own row
gather(measurement, size_in_cm, Sepal.Length:Petal.Width)
head(tidy_iris)
d <- read_csv("https://github.com/StanfordPsych254/Brown-Iannuzzi2016/blob/master/data/pilot_data.csv", na = c("", "NA"))
head(d)
library(tidyverse)
library(knitr)
library(ggplot2)
library(forcats)
library(car)
library(heplots)
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95.norm <- function(x) {
me <- sem(x) * qnorm(.975)
c(mean(x) - me, mean(x) + me)
}
knitr::opts_chunk$set(root.dir = normalizePath(".."))
d <- read_csv("https://github.com/StanfordPsych254/Brown-Iannuzzi2016/blob/master/data/pilot_data.csv", na = c("", "NA"))
head(d)
View(d)
View(d)
binom.test(5, 16, p=0.5, alternative = "greater")
binom.test(5, 16, p=0.5)
binom.test(5, 16, p=0.5, alternative = "greater")
binom.test(5, 16, p=0.5, alternative = "same")
binom.test(5, 16, p=0.5, alternative = "two.sided")
binom.test(5, 16, p=0.5, alternative = "greater")
binom.test(11, 22, p=0.5, alternative = "greater")
binom.test(17, 22, p=0.5, alternative = "greater")
binom.test(2, 19, p=0.5, alternative = "greater")
binom.test(2, 19, p=0.5, alternative = "two.sided")
binom.test(5, 16, p=0.5, alternative = "two.sided")
binom.test(5, 16, p=0.5, alternative = "greater")
ms.cond.bin <- d %>%
select(ID, condition, policy.bin) %>%
group_by(condition) %>%
summarize(ct.support = mean(policy.bin == "Support"))
ms.cond.bin <- d %>%
select(ID, condition, policy.bin) %>%
group_by(condition) %>%
summarize(pct.support = mean(policy.bin == "Support"))
ms.cond.bin <- d %>%
select(ID, condition, policy.bin) %>%
group_by(condition) %>%
summarize(pct.support = mean(policy.bin == "Support"))
ms.cond.bin <- d %>%
select(ID, condition, policy.bin) %>%
group_by(condition)
library(tidyverse)
library(ggplot2)
library(foreign)
library(forcats)
library(ggthemes)
library(car)
library(scales)
library(knitr)
library(heplots)
library(Hmisc)
library(psych)
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95.norm <- function(x) {
me <- sem(x) * qnorm(.975)
c(mean(x) - me, mean(x) + me)
}
ci <- function(x) {sem(x) * 1.96}
d$fit <- (d$fit_1 + d$fit_2 + d$fit_3)/3
power.t.test(n=null, sd=1, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(d=0.25, sd=1, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(d=0.25, sd=1, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
help power.t.test()
help("power.t.test")
power.t.test(delta=0.25, sd=1, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.25, sd=1, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.25, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.35, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.33, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=150, delta=NULL, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.38, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.4, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.25, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
power.t.test(n=NULL, delta=0.3, sd=1, power=0.80, sig.level=0.05, type = c("two.sample"), alternative=c("two.sided"))
\documentclass[11pt, a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{longtable, booktabs, tabularx, threeparttable, adjustbox}
\usepackage{amsmath, amssymb, amsthm, bbm, bm}
\usepackage{secdot, sectsty}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{geometry}
\usepackage{placeins}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{setspace}
rm(list =ls())
total = c(total = c(0.03425112, 0.086014, -0.0232975, 0.39984161, 0.27195879, 0.01003674, 0.02206008, -0.03887599, 0.02740939, 0.22397134))
ttest_total = t.test(total, alternative = c("greater"), mu = 0)
print(ttest_total)
total = c(total = c(0.03425112, 0.086014, -0.0232975, 0.53516674, 0.27195879, 0.01003674, 0.02206008, -0.03887599, 0.02740939, 0.0404))
ttest_total = t.test(total, alternative = c("greater"), mu = 0)
print(ttest_total)
total = c(total = c(0.0321, 0.1098, -0.0289, 0.7601, 0.6966, 0.0032, 0.0094, -0.0401, 0.0199, 0.1076))
ttest_total = t.test(total, alternative = c("greater"), mu = 0)
print(ttest_total)
??nmeans4
??n4means
library(CRTSize)
n4means(delta=0.25, sigma=1, m=60, alpha=0.05, power=0.8, AR=1, two.tailed=TRUE, digits=3)
n4means(delta=0.25, sigma=1, m=60, ICC=0.05, alpha=0.05, power=0.8, AR=1, two.tailed=TRUE, digits=3)
n4means(delta=0.25, sigma=1, m=60, ICC=0.015, alpha=0.05, power=0.8, AR=1, two.tailed=TRUE, digits=3)
n4means(delta=0.25, sigma=1, m=60, ICC=0.025, alpha=0.05, power=0.8, AR=1, two.tailed=TRUE, digits=3)
print("hello world")
rm(ls())
rm(ls())
rm(list =ls())
rm(list =ls())
knitr::opts_chunk$set(echo = TRUE)
library(CRTSize)
n4means(delta=0.25, sigma=1, m=60, ICC=0.02, alpha=0.05, power=0.8, AR=1, two.tailed=TRUE, digits=3)
## The required sample size is a minimum of 18 clusters of size 60 in the Experimental Group and a minimum of 18 clusters (size 60) in the Control Group.
setwd("~/Google Drive/UBIF/UBIF_Deliverables/UBIF_PAP/K1_PAP")
rm(list =ls())
